# Default configuration for the PDF extraction pipeline
# These settings can be overridden by creating a PipelineConfig object in code.

processing:
  # Maximum number of pages to process concurrently.
  concurrency_limit: 5
  
  # Enables or disables caching of LLM responses.
  cache_enabled: true
  
  # Time-to-live for cached items, in seconds (e.g., 3600 = 1 hour).
  cache_ttl: 3600
  
  # Maximum number of LLM API calls to make per minute.
  rate_limit_per_minute: 60
  
  # Maximum number of times to retry a failed LLM call.
  retry_max_attempts: 3
  
  # The base for the exponential backoff delay in retries.
  retry_backoff_base: 2.0
  
  # If all smart extraction strategies fail, this will fall back to raw text extraction.
  fallback_to_raw_text: true

chunking:
  # The target size for each text chunk, in tokens.
  chunk_size: 3000
  
  # The number of tokens to overlap between consecutive chunks.
  chunk_overlap: 200
  
  # The default chunking profile to use.
  profile: "standard"
  
  # The separators to use when splitting text into chunks.
  separators:
    - "\n\n"
    - "\n"
    - ". "
    - " "
    - ""